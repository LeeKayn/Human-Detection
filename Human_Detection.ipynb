{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #@title Choose model and run this cell\n",
    "model_path=\"/home/leekayn/.cache/huggingface/hub/models--JunkyByte--easy_ViTPose/snapshots/2757e82adcccda02f9f7fef66e5a115b7be439fe/torch/wholebody/vitpose-b-wholebody.pth\"\n",
    "yolo_path=\"/home/leekayn/.cache/huggingface/hub/models--JunkyByte--easy_ViTPose/snapshots/2757e82adcccda02f9f7fef66e5a115b7be439fe/yolov8/yolov8s.pt\"\n",
    "# !pip install huggingface_hub\n",
    "# MODEL_SIZE = 's'  #@param ['s', 'b', 'l', 'h']\n",
    "# YOLO_SIZE = 's'  #@param ['s', 'n']\n",
    "# DATASET = 'wholebody'  #@param ['coco_25', 'coco', 'wholebody', 'mpii', 'aic', 'ap10k', 'apt36k']\n",
    "# ext = '.pth'\n",
    "# ext_yolo = '.pt'\n",
    "# \n",
    "# \n",
    "# import os\n",
    "# from huggingface_hub import hf_hub_download\n",
    "# MODEL_TYPE = \"torch\"\n",
    "# YOLO_TYPE = \"torch\"\n",
    "# REPO_ID = 'JunkyByte/easy_ViTPose'\n",
    "# FILENAME = os.path.join(MODEL_TYPE, f'{DATASET}/vitpose-' + MODEL_SIZE + f'-{DATASET}') + ext\n",
    "# FILENAME_YOLO = 'yolov8/yolov8' + YOLO_SIZE + ext_yolo\n",
    "# \n",
    "# print(f'Downloading model {REPO_ID}/{FILENAME}')\n",
    "# model_path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME)\n",
    "# yolo_path = hf_hub_download(repo_id=REPO_ID, filename=FILENAME_YOLO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:52:29.824498Z",
     "start_time": "2024-02-28T15:52:29.818302Z"
    }
   },
   "id": "a077fcc2a6d5e61d",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:52:32.811592Z",
     "start_time": "2024-02-28T15:52:30.269195Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_SIZE = 'b'\n",
    "DATASET = 'wholebody'\n",
    "from easy_ViTPose import VitInference\n",
    "model = VitInference(model_path, yolo_path, MODEL_SIZE,\n",
    "                     dataset=DATASET, yolo_size=320, is_video=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Đường dẫn tới file ảnh trên máy của bạn\n",
    "file_path = 'ronaldo1.jpg'\n",
    "image=cv2.imread(file_path)\n",
    "# Load ảnh từ file\n",
    "img = np.array(Image.open(file_path), dtype=np.uint8)\n",
    "# Tiếp tục với quá trình xử lý ảnh và inference như bạn đã làm\n",
    "frame_keypoints = model.inference(img)\n",
    "img,bboxes = model.draw()\n",
    "# Tìm điểm tâm của các bounding box\n",
    "bboxes_centers = []\n",
    "for bbox in bboxes:\n",
    "  x1, y1, x2, y2 = bbox\n",
    "  center_x = (x1 + x2) / 2\n",
    "  center_y = (y1 + y2) / 2\n",
    "  bboxes_centers.append((center_x, center_y))\n",
    "\n",
    "# Tính khoảng cách từ điểm tâm đến các cạnh của khung hình\n",
    "distances_to_edges = []\n",
    "for center in bboxes_centers:\n",
    "  distance_to_left = center[0]\n",
    "  distance_to_right = img.shape[1] - center[0]\n",
    "  distance_to_top = center[1]\n",
    "  distance_to_bottom = img.shape[0] - center[1]\n",
    "  distances_to_edges.append([distance_to_left, distance_to_right, distance_to_top, distance_to_bottom])\n",
    "\n",
    "# Tìm bounding box có điểm tâm gần khung hình nhất\n",
    "min_distance_index = np.argmin(np.sum(distances_to_edges, axis=1))\n",
    "\n",
    "# Cắt ảnh dựa trên bounding box sát khung hình nhất\n",
    "cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "# Hiển thị ảnh đã cắt\n",
    "cv2.imshow(\"Cropped Image\", cropped_image)\n",
    "\n",
    "# Hiển thị hình ảnh bằng OpenCV\n",
    "cv2.imshow('Image', img[..., ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:52:38.654769Z",
     "start_time": "2024-02-28T15:52:32.813115Z"
    }
   },
   "id": "d73c9043c5aa2f27",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5a9f0eb9a977814e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
